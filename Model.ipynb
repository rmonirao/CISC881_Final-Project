{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv3D, MaxPooling3D\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_array = np.load(\"/Users/katyadunets/Desktop/processed_3D_array.npy\")\n",
    "class_array = np.load(\"/Users/katyadunets/Desktop/classes.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5166, 40, 40, 40)\n",
      "(5166,)\n"
     ]
    }
   ],
   "source": [
    "print(large_array.shape)\n",
    "print(class_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(large_array, class_array, test_size = 0.20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 40, 40, 40, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 40, 40, 40, 1)\n",
    "input_shape = (40, 40, 40, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling3D(pool_size=(3, 3, 3)))\n",
    "model.add(Dropout(0.30))\n",
    "\n",
    "model.add(Conv3D(64, (3, 3, 3), activation='relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "model.add(Dropout(0.30))\n",
    "\n",
    "model.add(Conv3D(128, (3, 3, 3), activation='relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "model.add(Dropout(0.30))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attempted with focal loss, but does not improve accuracy so using binary cross-entropy\n",
    "def focal_loss(gamma=2., alpha=.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n",
    "    \n",
    "    return focal_loss_fixed\n",
    "\n",
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3099 samples, validate on 1033 samples\n",
      "Epoch 1/10\n",
      "3099/3099 [==============================] - 577s 186ms/step - loss: 0.6550 - acc: 0.6225 - val_loss: 0.6107 - val_acc: 0.6312\n",
      "Epoch 2/10\n",
      "3099/3099 [==============================] - 563s 182ms/step - loss: 0.5946 - acc: 0.6902 - val_loss: 0.5894 - val_acc: 0.6834\n",
      "Epoch 3/10\n",
      "3099/3099 [==============================] - 563s 182ms/step - loss: 0.5629 - acc: 0.7222 - val_loss: 0.5056 - val_acc: 0.7909\n",
      "Epoch 4/10\n",
      "3099/3099 [==============================] - 563s 182ms/step - loss: 0.4875 - acc: 0.7874 - val_loss: 0.4401 - val_acc: 0.7967\n",
      "Epoch 5/10\n",
      "3099/3099 [==============================] - 560s 181ms/step - loss: 0.4450 - acc: 0.8006 - val_loss: 0.4080 - val_acc: 0.8122\n",
      "Epoch 6/10\n",
      "3099/3099 [==============================] - 545s 176ms/step - loss: 0.4063 - acc: 0.8228 - val_loss: 0.4127 - val_acc: 0.8219\n",
      "Epoch 7/10\n",
      "3099/3099 [==============================] - 509s 164ms/step - loss: 0.3873 - acc: 0.8345 - val_loss: 0.4045 - val_acc: 0.8170\n",
      "Epoch 8/10\n",
      "3099/3099 [==============================] - 508s 164ms/step - loss: 0.3732 - acc: 0.8358 - val_loss: 0.3972 - val_acc: 0.8228\n",
      "Epoch 9/10\n",
      "3099/3099 [==============================] - 571s 184ms/step - loss: 0.3600 - acc: 0.8477 - val_loss: 0.4208 - val_acc: 0.8170\n",
      "Epoch 10/10\n",
      "3099/3099 [==============================] - 571s 184ms/step - loss: 0.3683 - acc: 0.8403 - val_loss: 0.3991 - val_acc: 0.8287\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x10e543978>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.399673682693356\n",
      "Test accuracy: 0.8346228238692367\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 38, 38, 38, 64)    1792      \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 12, 12, 12, 64)    0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 12, 12, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 10, 10, 10, 64)    110656    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 5, 5, 5, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5, 5, 5, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 3, 3, 3, 128)      221312    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 1, 1, 1, 128)      0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 1, 1, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               38700     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 301       \n",
      "=================================================================\n",
      "Total params: 372,761\n",
      "Trainable params: 372,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "predictions = model.predict(x_test)\n",
    "c = confusion_matrix(y_test, predictions.round())\n",
    "\n",
    "print('Confusion matrix:\\n', c)\n",
    "print('specificity', c[0, 0] / (c[0, 1] + c[0, 0]))\n",
    "print('sensitivity', c[1, 1] / (c[1, 1] + c[1, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8715848322800194"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "fpr_keras, tpr_keras, thresholds = roc_curve(y_test, predictions)\n",
    "auc = roc_auc_score(y_test, predictions)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"/Users/katyadunets/Desktop/fpr.npy\", fpr_keras)\n",
    "np.save(\"/Users/katyadunets/Desktop/tpr.npy\", tpr_keras)\n",
    "np.save(\"/Users/katyadunets/Desktop/auc.npy\", auc)\n",
    "np.save(\"/Users/katyadunets/Desktop/y_test.npy\", y_test)\n",
    "np.save(\"/Users/katyadunets/Desktop/predictions.npy\", predictions)\n",
    "\n",
    "#issue with importing matplotlib into tensorflow environment - so these arrays were saved separately for \n",
    "#plotting in Spyder, however the plotting code is available below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr, label='ROC Curve (area = {:.3f})'.format(auc), color = 'red')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "c = confusion_matrix(y_true = y_test, y_pred = predictions.round())\n",
    "sn.heatmap(c, annot=True)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
